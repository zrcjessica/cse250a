{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_matrices(file_f):\n",
    "    l = np.zeros([81,81])\n",
    "    with open(file_f, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.split()\n",
    "            l[int(line[1])-1,int(line[0])-1] = float(line[2]) # [s',s]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = load_matrices('hw9_prob_a1.txt')\n",
    "a2 = load_matrices('hw9_prob_a2.txt')\n",
    "a3 = load_matrices('hw9_prob_a3.txt')\n",
    "a4 = load_matrices('hw9_prob_a4.txt')\n",
    "rewards = np.loadtxt('hw9_rewards.txt')\n",
    "gamma = 0.9925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions = ['W', 'N', 'E', 'S']  # west, east, north, south"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 9.3 (a) Compute optimal policy $\\pi^{*}(s)$ and optimal value function $V^*(s)$ using policy iteration\n",
    "- $\\pi'(s) = argmax_{a}[\\sum_{s'}P(s'|s,a)V^{\\pi}(s')]$\n",
    "- $V^{\\pi}=R(s)+\\gamma\\sum_{s'}P(s'|s,\\pi(s))V^{\\pi}(s')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_dict = {'W': a1, 'N': a2, 'E': a3, 'S': a4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def policy_eval(policy):\n",
    "    g_matrix = np.zeros([81,81])\n",
    "    i_matrix = np.identity(81)\n",
    "    \n",
    "    states = range(81)  # fix\n",
    "    for i in range(len(states)):       # s\n",
    "        for j in range(len(states)):   # s'\n",
    "            g_matrix[i,j] = gamma*action_dict[policy[i]][j,i]\n",
    "    i_g_matrix = i_matrix - g_matrix\n",
    "    x = np.dot(np.linalg.inv(i_g_matrix),rewards)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greedy(old_policy, v_list): \n",
    "    states = range(81) # fix\n",
    "    pi_vals = np.full([len(states),len(actions)],-np.inf)\n",
    "    # compute all values\n",
    "    for a in range(len(actions)):\n",
    "        for s in range(len(states)):\n",
    "            pi_vals[s,a] = sum([action_dict[actions[a]][sp,s] * v_list[sp] for sp in range(81)])\n",
    "    # find best action for each row \n",
    "    best_actions = [actions[np.argmax(row)] for row in pi_vals]\n",
    "    return best_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_policy():\n",
    "    l = []\n",
    "    states = range(81)  # fix\n",
    "    for i in range(len(states)):  # 81\n",
    "        l.append(random.choice(actions))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def policy_iteration():\n",
    "    # initiate policy at random\n",
    "    policy = generate_policy()\n",
    "    state_value_func = policy_eval(policy)\n",
    "\n",
    "    # repeat until convergence\n",
    "    while True:\n",
    "        new_policy = greedy(policy, state_value_func)\n",
    "        new_state_value_func = policy_eval(new_policy)\n",
    "\n",
    "        # check if converged\n",
    "        if all(state_value_func == new_state_value_func):\n",
    "            break\n",
    "\n",
    "        policy = new_policy\n",
    "        state_value_func = new_state_value_func\n",
    "    \n",
    "    new_policy = np.array(new_policy).reshape(9,9)\n",
    "    return new_policy.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['W' 'W' 'W' 'W' 'W' 'W' 'W' 'W' 'W']\n",
      " ['W' 'E' 'E' 'S' 'W' 'W' 'S' 'W' 'W']\n",
      " ['E' 'N' 'W' 'S' 'W' 'W' 'S' 'W' 'W']\n",
      " ['W' 'W' 'S' 'W' 'W' 'W' 'S' 'W' 'W']\n",
      " ['W' 'W' 'S' 'W' 'W' 'W' 'S' 'W' 'W']\n",
      " ['W' 'S' 'W' 'W' 'W' 'W' 'S' 'W' 'W']\n",
      " ['W' 'S' 'W' 'E' 'E' 'E' 'E' 'E' 'W']\n",
      " ['W' 'E' 'E' 'N' 'W' 'E' 'E' 'N' 'W']\n",
      " ['W' 'W' 'W' 'W' 'W' 'W' 'W' 'W' 'W']]\n"
     ]
    }
   ],
   "source": [
    "print policy_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
